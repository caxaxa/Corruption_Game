{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Approach to Leniency Policies in Collusive Corruption\n",
    "\n",
    "This Notebook builds an economic model of non-trial resolutions for collusive corruption. It uses discrete time and discrete state dynamic programming to solve the agents' decision problem.\n",
    "\n",
    "## Overview\n",
    "\n",
    "    1) Settle the Basic Model, the relevant constants and variables; \n",
    "\n",
    "    2) Build the Transition functions;\n",
    "\n",
    "    3) Build the Reward Function;\n",
    "\n",
    "    4) Find the optimal policy from **one player** given a greedy policy from the other player; and\n",
    "\n",
    "    5) Use optimal policicies found and iterate until convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check matplotlib version.... ax.bar_label is available only in the 3.5+\n",
    "# !pip install quantecon\n",
    "#!pip install matplotlib -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import quantecon as qe\n",
    "import scipy.sparse as sparse\n",
    "from quantecon import compute_fixed_point\n",
    "from quantecon.markov import DiscreteDP\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext itikz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir Plottings\n",
    "\n",
    "# #if colab:\n",
    "# !wget https://raw.githubusercontent.com/caxaxa/Corruption_Game/main/Plotting_Functions.ipynb\n",
    "# !wget https://raw.githubusercontent.com/caxaxa/Corruption_Game/main/Tests.ipynb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%run Plotting_Functions.ipynb  #Notebook with the plotting functions created for these specific outputs\n",
    "%run Tests.ipynb  #Notebook with tests from the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "Given the following constants $\\theta$ for all periods $t$ and all agents $i \\in (payer,receiver)$:\n",
    "\n",
    "\n",
    "* Let $b$ be the fixed price of the bribes;\n",
    "\n",
    "* Let $a$ be the gains from corruption to the payer;\n",
    "\n",
    "* The cost from perfoming the corruption favour from the bribe receiver is $c_r$ ;\n",
    "\n",
    "* Let $f$ be the monetary fines for agents caught in corruption;\n",
    "\n",
    "* $i$ is the interest rate;\n",
    "\n",
    "* $\\delta$ is the liability depreciation or prescription;\n",
    "\n",
    "* $\\gamma$ is the time discount;\n",
    "\n",
    "* $\\eta$ is the agents' risk aversion;\n",
    "\n",
    "* $y_0$ is an autonomous non-financial income;\n",
    "\n",
    "* Probability of detection is $\\alpha$; and\n",
    "\n",
    "* Probability of conviction is $\\beta$.\n",
    "\n",
    "#### Leniency rules:\n",
    "\n",
    "* $R$ sanction reduction for unilateral self-reporting before detection;\n",
    "\n",
    "* $r$ sanction reduction for simultaneously self-reporting before detection;\n",
    "\n",
    "* $P$ sanction reduction for unilateral self-reporting after detection; and\n",
    "\n",
    "* $p$ sanction reduction for simultaneously self-reporting after detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Constants are in globals\n",
    "\n",
    "b = 2 # Bribe\n",
    "a = 7 # Advantage From Corruption\n",
    "c_b = 0 # Cost of Corrutpion for the receiver\n",
    "f = 5 # Fine for corruption\n",
    "\n",
    "alpha = 0.2 # Probability of detection from authorities\n",
    "beta = 0.6 # Probability of judicial conviction\n",
    "\n",
    "ir = 0.1 # Interest Rates\n",
    "delta = 0.2 # Liability Depreciation\n",
    "\n",
    "gamma = 0.98 # Time discount\n",
    "eta = 0.9 # Risk Aversion\n",
    "\n",
    "\n",
    "y0 = 0 # Non-financial income\n",
    "yl = b #leaving wage\n",
    "\n",
    "\n",
    "# Defining the constants of sanction reduction\n",
    "R = 0\n",
    "\n",
    "r = 0.6\n",
    "\n",
    "P = 0.75\n",
    "\n",
    "p = 0.9\n",
    "\n",
    "\n",
    "# Defining the players in the instance\n",
    "\n",
    "player = 'payer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_otherplayer(player):\n",
    "    if player == 'payer':\n",
    "        return 'receiver'\n",
    "    else:\n",
    "        return 'payer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States and Actions:\n",
    "\n",
    "This example is built using discrete time, decisions and states:\n",
    "\n",
    "#### A set of discrete actions or decisions (controls)  $\\mathbf{d}_{i,t}$\n",
    "\n",
    "The decision regarding corruption $d{i,t}$ can assume 3 different values:\n",
    "\n",
    "* $not_{i,t}$ agents can choose to do nothing; \n",
    "\n",
    "* $cor_{i,t}$ is the decision from player $i$ to pay/receive a bribe in time $t$; and\n",
    "\n",
    "* $rep_{i,t}$ is the decision from player $i$ to self-report.\n",
    "\n",
    "Agents decide how much they are going to consume at each time $c_t$.\n",
    "A complementary way to represent the consumpion decision, is the decision of how much to save $w$, or buy financial assets.\n",
    "\n",
    "* $w_{i,t}$ is the decision of how much to save, can go from 0 to $(W_t)$\n",
    "\n",
    "#### A set of discrete states  $\\textbf{x}_{i,t}$\n",
    "\n",
    "##### State of the world $S$\n",
    "\n",
    "* $S_{i,t}$ is the state of the world at time $t$;\n",
    "\n",
    "* $s_{nc}$ is the state of the world where neither players are in corruption;\n",
    "\n",
    "* $s_{cor}$ is the state of the world where both agents succeded in corruption;\n",
    "\n",
    "* $s_{det,i}$ is the state of the world where the agent $i$ is detected for corruption;\n",
    "\n",
    "* $s_{con,i}$ is the state of the world where the agent $i$ is convicted;\n",
    "\n",
    "* $s_{acq,i}$ is the state of the world where the agent $i$ is acquitted;\n",
    "\n",
    "* $s_{sr,i}$ is the state of the world where the agent $i$ self-reported before being detected;\n",
    "\n",
    "* $s_{pg,i}$ is the state of the world where the agent $i$ plead guilty;\n",
    "\n",
    "and\n",
    "\n",
    "* The states of the world $( s_{nc}, s_{cor}, s_{det,i}, s_{col,i}, s_{con,i},s_{acq,i}, s_{sr,i}, s_{pg,i}) \\in S$;\n",
    "\n",
    "##### Wealth from Players\n",
    "\n",
    "* $W_{i,t}$ are the assets from player $i$ at time $t$. It goes from 0 to a maximum of $\\overline{W}$;\n",
    "\n",
    "##### Liability from Players\n",
    "\n",
    "* $L_{i,t}$ is the wealth from player $i$ at time $t$. It goes from 0 to a maximum of $\\overline{L}$;\n",
    "\n",
    "#### State and Action \n",
    "\n",
    "* Lastly, the states $( W_{i,t}, L_{i,t},S_{i,t}) \\in \\textbf{x}_{i,t}$ and the actions $(d_{i,t},w{i,t}) \\in \\mathbf{d}_{it}$.\n",
    "\n",
    "In summary:\n",
    "$\n",
    "\\begin{equation*}\n",
    "\t\\mathbf{d}_{t} \\equiv\n",
    "\t\\begin{bmatrix}\n",
    "\t\td_{t} \\\\\n",
    "\t\tw_{t} \\\\  \n",
    "\t\\end{bmatrix}\\textrm{, and }\n",
    "\t\\mathbf{x}_{t}\\equiv\n",
    "\t\\begin{bmatrix}\n",
    "\t\tW_{t}\\\\\n",
    "\t\tL_{t}\\\\\n",
    "\t\tS_{t}\n",
    "\t\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "### State and Action Spaces\n",
    "\n",
    "Let $\\mathbf{x}$ be the entire state-space. If,\n",
    "\n",
    "$W \\in [0,...,\\bar{W}]$,\n",
    "\n",
    "$L \\in [0,...,\\bar{L}]$, and\n",
    "\n",
    "$S \\in [s_{nc},s_{cor},s_{des},s_{det},s_{con},s_{acq},s_{sr},s_{pg}]$,\n",
    "\n",
    "then,\n",
    "\n",
    "$ \\mathbf{x} = [W,L,S] $ and has dimention $(3 \\times (\\bar{W}*\\bar{L}*8))$.\n",
    "\n",
    "* Let $\\mathbf{d}$ be the entire action or control-space. If,\n",
    "\n",
    "$d \\in [not_{i,t},cor_{i,t},rep_{i,t}]$ and\n",
    "\n",
    "$a = [0,...,\\bar{W}]$, then\n",
    "\n",
    "$ \\mathbf{d} = [a,d] $ and has dimention $(2 \\times (\\bar{W}*3))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximun wealth from corruption:\n",
    "W_bar = 10\n",
    "\n",
    "#create the wealth statespace:\n",
    "W_space = np.arange(0,W_bar+1)\n",
    "\n",
    "#maximum liability\n",
    "L_bar = 5\n",
    "\n",
    "#create the wealth statespace:\n",
    "L_space = np.arange(0,L_bar+1)\n",
    "\n",
    "#creat the actionspace:\n",
    "# It is better to identify all decisions in one column than having a column to each binary decision. Because:\n",
    "# 1 - It enhances readibility;\n",
    "# 2 - Imply that agents cannot make two decisions in the same state; and\n",
    "# 3 - It makes no difference in the lenth of the feasible action-space.\n",
    "d_not = 0 # do nothing\n",
    "d_cor = 1 # pay a bribe\n",
    "d_rep = 2 # report a crime\n",
    "\n",
    "d_space = np.array([d_not,d_cor,d_rep])\n",
    "\n",
    "#create the saving space:\n",
    "w_space =  np.arange(0,W_bar+1)\n",
    "\n",
    "# state of the world space\n",
    "# It is better to use integers as ids so the arrays for the state-spaces preserve integer as the main data type. \n",
    "s_nc  = 0\n",
    "s_cor = 1\n",
    "s_det = 2\n",
    "s_des = 3\n",
    "s_con = 4\n",
    "s_acq = 5\n",
    "s_sr = 6\n",
    "s_pg = 7\n",
    "\n",
    "S_space = np.array([s_nc,s_cor,s_det,s_des,s_con,s_acq,s_sr,s_pg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from states an Actions (Payoffs)\n",
    "\n",
    "#### Returns from Corruption \n",
    "\n",
    "It is possible to write the corruption in terms of payoffs $\\pi_{i,t+1}(d)$ and costs $\\phi_{i,t}(d)$ for players.\n",
    "\n",
    "Or else, if players choose to pay a bribe then:\n",
    "\n",
    "$\\pi_{payer} = a$ and, $\\pi_{receiver} = b$. \n",
    "\n",
    "Also, $\\phi_{payer} = b$ and, $\\phi_{receiver} = c_{b}$.\n",
    "\n",
    "Moreover, the cost and the return for players from not entering in bribery is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost and return functions\n",
    "def get_pi_i(player, Si):#return from bribery\n",
    "    if Si == s_cor: ## substitute by the function S_prime to get pi_prime of d_t.\n",
    "        if player == 'payer':\n",
    "            return a\n",
    "        else:\n",
    "            return b\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def get_phi_i(player, di,dj): #cost from bribery\n",
    "    if di == 1 and dj == 1:\n",
    "        if player == 'payer':\n",
    "            return b\n",
    "        else:\n",
    "            return c_b\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criminal liability $l$\n",
    "\n",
    "Agents are liable for each crime $l_t$ they commited. \n",
    "\n",
    "Each bribe paid generates a criminal liability $l$ in the next period.\n",
    "\n",
    "Nonetheless, liability from crimes tend to depreciate at a rate $\\delta$ over time. \n",
    "\n",
    "The history of the liabilities is expressed by the state $L_t$ each period.\n",
    "\n",
    "$l_{t}(d) = \\begin{cases}\n",
    "\t1 \\textrm{   if colluding and } d_{t} = 1 \\\\\n",
    "\t-1 \\textrm{   if desisted and } d_{t} = 0 \\\\\n",
    "    0 \\textrm{  else}\\end{cases}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liability from crimes\n",
    "def get_li_prime(di, dj, S_prime):\n",
    "    if S_prime == s_des:\n",
    "        return -1\n",
    "    elif di == 1 and dj == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanctions $s$\n",
    "\n",
    "If agents are convicted for corruption ($s_{con}$), they pay a monetary $s$.\n",
    "\n",
    "The sanction depends on the fine $f$ for each crime that they are liable at that time $L_t$.\n",
    "\n",
    "If agents, decide do self-report their misconducts before being detected they recieve a reduction from the sanction.\n",
    "\n",
    "The reduction is $R$ if they unilaterealy report, or $r$ if they report together.\n",
    "\n",
    "If agents, decide do self-report their misconducts after being detected they recieve a reduction from the sanction.\n",
    "\n",
    "The reduction is $P$ if they unilaterealy report, or $p$ if they report together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanction from crimes\n",
    "def get_si(Li ,Si,Sj):\n",
    "    if Li == 0:\n",
    "        return 0\n",
    "    elif Si == s_con:\n",
    "        return f*Li + (get_pi_i(player,1)/(gamma**(Li*2)))*(Li-1)  # discounted gain from corruption\n",
    "    elif Si == s_sr:\n",
    "        if Sj == s_sr:\n",
    "            return r*f*Li + (get_pi_i(player,1)/(gamma**(Li*2)))*(Li-1)\n",
    "        else:\n",
    "            return R*f*Li + (get_pi_i(player,1)/(gamma**(Li*2)))*(Li-1)\n",
    "    elif Si == s_pg:\n",
    "        if Sj == s_pg:\n",
    "            return p*f*Li + (get_pi_i(player,1)/(gamma**(Li*2)))*(Li-1)\n",
    "        else:\n",
    "            return P*f*Li + (get_pi_i(player,1)/(gamma**(Li*2)))*(Li-1)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Financial Income $y_f$:\n",
    "\n",
    "Financial income $y_f$ is given by the interest rates $r$ over the savings $w$.\n",
    "\n",
    "#### Corruption Income $y_c$:\n",
    "\n",
    "\n",
    "Now it is possible to define the agents income.\n",
    "\n",
    "At each period $t$ the agents $i$ have an income that depends on their current state:\n",
    "\n",
    "\n",
    "For $y_c \\in (0,\\pi,s,Rs,rs,Ps,ps)$ let,\n",
    "\n",
    "$y_{c ~ t}(\\mathbf{x}_t) = \\begin{cases}\n",
    "\t0\\textrm{   if not colluding}\\\\\n",
    "\t\\pi \\textrm{   if colluding}\\\\\n",
    "\t0\\textrm{   if desisted} \\\\\n",
    "\t s\\textrm{   if Convicted } \\\\\n",
    "\t0 \\textrm{ if Acquitted } \\\\\n",
    "    Rs \\textrm{ if Reported alone before detection } \\\\\n",
    "    rs \\textrm{ if reported simultaneously before detection}\\\\\n",
    "    Ps \\textrm{ if Reported alone after detection } \\\\\n",
    "    ps \\textrm{ if reported simultaneously after detection}\n",
    "\t\\end{cases}$.\n",
    "    \n",
    "    \n",
    "Lastly, $W_t = y_0+ y_f + y_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income        \n",
    "def get_yfi_prime(w):\n",
    "    return int(round((1 + ir)*w))\n",
    "\n",
    "def get_yfc_prime(player, L_prime, Si_prime, Sj_prime):\n",
    "    return get_pi_i(player, Si_prime) - get_si(L_prime, Si_prime, Sj_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "#### Expected return\n",
    "\n",
    "$$ - \\phi + \\gamma E \\left[ \\sum_{\\mathbf{x}} (\\pi - s) \\right] $$\n",
    "\n",
    "It is convenient to define the expected return from corruption. Or else, the return $y_{c ~ t}$ that agents expect to have given their state $\\mathbf{x_t}$ and decisions $\\mathbf{d_t}$.\n",
    "\n",
    "$$E\\left[ y_{c~ i,t} | \\mathbf{x}_{i,t},\\mathbf{d}_{i,t} \\right] = E\\left[-\\phi_{i,t}(d_{i,t},d_{j,t}) \\right]+ E\\left[\\pi_{i,t+1}(di,dj) \\right]+ E\\left[ s_{i,t+1}(L_{i,t+1},di,dj)\\right]$$\n",
    "\n",
    "For exemple, if $d_i = d_{cor}$ and $d_j = d_{cor}$:\n",
    "\n",
    "$$E\\left[ y_{c ~ i,t} | \\mathbf{x}_{i,t},\\mathbf{d}_{i,t} \\right] = -\\phi_{i,t}(d_{i,t},d_{j,t}) + (1+\\alpha)\\pi_{i,t+1}(di,dj) + \\alpha \\beta s_{i,t+1}(L_{i,t+1},di,dj)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected retrun next period from corruption.\n",
    "def expected_return_i(player, L_prime, W_prime):\n",
    "    return - get_phi_i(player, d_cor , d_cor) + gamma *((1-alpha)*get_pi_i(player, s_cor) + alpha*beta*get_si(L_prime, s_con , s_con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laws of motion\n",
    "\n",
    "$$\\mathbf{x}_{t+1} = x ( \\mathbf{x}_t , \\mathbf{d}_t , \\varepsilon_{t+1} ; \\theta ) $$\n",
    "\n",
    "Where $\\theta$ is a vector of constant parameters.\n",
    "\n",
    "And $\\varepsilon \\sim Bernoulli ~ (\\alpha)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Wealth transition rule\n",
    "In this specific example we have:\n",
    "\n",
    "$$W_{i,t+1} = y_{f ~ i,t+1}  + y_{c ~ i,t+1} + y_0 $$\n",
    "\n",
    "where,\n",
    "\n",
    "$$ y_{f ~ i,t+1}  = (1+r)w_{i,t}$$ or,\n",
    "\n",
    "$$ w_{i,t}  = W_{i,t} - c_{i,t} - \\phi{i,t} $$\n",
    "\n",
    "Since wealth increases because of income. Be it from, financial investments, corruption or non-financial income.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# What is not saved is totally consumed in t or paid in phi\n",
    "def get_Wi_prime(player, wi, L_prime, Si_prime, Sj_prime):\n",
    "    if y0 + get_yfi_prime(wi) + get_yfc_prime(player, L_prime, Si_prime, Sj_prime) > yl:\n",
    "        if y0 + get_yfi_prime(wi) + get_yfc_prime(player, L_prime, Si_prime, Sj_prime) <= W_bar:\n",
    "            return int(round(y0 + get_yfi_prime(wi) + get_yfc_prime(player, L_prime, Si_prime, Sj_prime)))\n",
    "        else:\n",
    "            return W_bar\n",
    "    elif y0 + get_yfi_prime(wi) + get_yfc_prime(player, L_prime, Si_prime, Sj_prime) > 0:\n",
    "        return int(round(y0 + get_yfi_prime(wi) + get_yfc_prime(player, L_prime, Si_prime, Sj_prime))) + yl  \n",
    "    else:\n",
    "        return yl ### or y0 -> Depends on the hypothesis... if Wi is negative the players use or not the y0 to pay the Fines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liability transition rule\n",
    "\n",
    "$$L_{i,t+1} = (1-d)L_{i,t} + l_{i,t+1} $$\n",
    "\n",
    "Liability decays over time. Because information gets lost over time and also because of prescripion rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Li_prime(Li,di,dj,Si_prime):\n",
    "    if Si_prime == s_nc: # There are no Liabilities after judgments\n",
    "        return 0\n",
    "    elif ((Li + get_li_prime(di, dj,Si_prime) > 0) and (Li + get_li_prime(di, dj,Si_prime) <= L_bar)) :\n",
    "        return Li + get_li_prime(di, dj, Si_prime)\n",
    "    elif Li + get_li_prime(di, dj,Si_prime) > L_bar :\n",
    "        return L_bar\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "################################### no decrease after 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S_{t+1} = S(\\varepsilon, S_t|d_t) $$\n",
    "\n",
    "The transition rule for $s$ is better represented by the diagram bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%itikz\n",
    "# \\documentclass[tikz]{standalone}\n",
    "# \\begin{document}\n",
    "\n",
    "\n",
    "# \\usetikzlibrary{decorations.pathreplacing,angles,quotes,calc,positioning,plotmarks}\n",
    "# \\usetikzlibrary{shapes.geometric, arrows, automata,arrows,positioning,calc}\n",
    "# \\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black]\n",
    "# \\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black]\n",
    "# \\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black]\n",
    "# \\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black]\n",
    "# \\tikzstyle{arrow} = [thick,->,>=stealth]\n",
    "\n",
    "# \\begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=2cm]\n",
    "# \t\t\\tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]\n",
    "# \t\t\\node[state]    (A)        \t\t       {No Corrup.};\n",
    "# \t\t\\node[state]    (B)[above right of= B]  at (2.5,2)\t     \t {Detected};\n",
    "# \t\t\\node[state]    (C)[below right of= B]\tat (2.5,-1.5)\t         {Colluding};\n",
    "# \t\t\\node[state]    (D)[right of= B]  at (6,0)\t\t\t\t { Desisted };\n",
    "# \t\t\\node[state]    (E)[right of= B]  at (2,0)\t\t\t\t { Convicted };\n",
    "# \t\t\\node[state]    (F)[right of= B]  at (2,-6)\t\t\t\t { Collab. };\n",
    "# \t\t\\path\n",
    "# \t\t(A) edge[loop left, left]\t    \t         node{1}   \t\t        (A)\n",
    "# \t\t(A) edge[bend right,below]    \t\t\t     node{2}        \t\t(C)\n",
    "# \t\t(A) edge[right,below]    \t\t\t         node{3}        \t\t(B)                     \n",
    "# \t\t(C) edge[loop below, above]    \t\t\t\t node{4}            \t(C)                  \n",
    "# \t\t(C) edge[very near end,bend left, right]   \t node{5}            \t(B)\n",
    "# \t\t(B) edge[bend right,above]    \t\t\t\t node{6*}            \t(A)\n",
    "# \t\t(C) edge [bend right,below]             \t node{7}                (D)\n",
    "# \t\t(D) edge [bend right,above]     \t         node{8}                (C)\n",
    "# \t\t(D) edge[loop right]\t      \t\t\t\t node{9}                (D)\n",
    "# \t\t(D) edge[bend right,above]    \t\t\t\t node{10}            \t(B)\n",
    "# \t\t(D) edge [above]    \t\t\t\t\t\t node{11}            \t(E)\n",
    "# \t\t(B) edge    \t\t\t\t\t\t\t\t node{12}            \t(E)\n",
    "# \t\t(C) edge    \t\t\t\t\t\t\t\t node{13}            \t(E)\n",
    "# \t\t(B) edge[very near end,bend right,left]      node{14}               (F)                    \n",
    "# \t\t(D) edge[bend left]                \t\t\t node{15}               (F)\n",
    "# \t\t(C) edge[bend left]                \t\t\t node{16}               (F)\n",
    "# \t\t(F) edge[bend left]                \t\t\t node{17}               (A)\n",
    "# \t\t(E) edge[above]                  \t\t\t node{18}               (A);\n",
    "# \t\\end{tikzpicture}\n",
    "# \\end{document}\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Transition Rule for S(x'|x,d)\n",
    "\n",
    "1) If no bribe is paid, the agent stays in the state not corruption. They can agree in corruption only if both parties join.: \n",
    "\n",
    "* $p(x' = s_{nc} | x = s_{nc}, d_i = 0 ~ or ~  d_j = 0) = 1$\n",
    "\n",
    "2) Agents go from not no corruption to corruption when they pay bribe with probability (1 - $\\alpha$) \n",
    "\n",
    "* $p(x' = s_{cor} | x = s_{nc}, d_i = 1 ~ and ~ dj_1) = 1 - \\alpha$\n",
    "\n",
    "3) If agents pay a bribe they can go from no corruption to detected with probability ($\\alpha$)\n",
    "\n",
    "* $p(x' = s_{det} | x = s_{nc}, d_i = 1 ~ and ~ d_j=1 ) = \\alpha$\n",
    "\n",
    "4) Agents stay in corruption if they keep paying bribes with probability  (1 - $\\alpha$) \n",
    "\n",
    "* $p(x' = s_{cor} | x = s_{corr}, d_i = 1 ~ and ~ d_j=1) = 1 - \\alpha$\n",
    "\n",
    "5) If agents pay a bribe they can go from corruption to detected with probability ($\\alpha$)\n",
    "\n",
    "* $p(x' = s_{det} | x = s_{nc}, d_i = 1 ~ and ~ d_j=1) = \\alpha$\n",
    "\n",
    "6) * If agents are detected and they do not plea guilty, they are acquitted with probability $(1-\\beta)$. After, they go back to the state with no corrution.\n",
    "\n",
    "* $p(x' = s_{acq} | x = s_{cor}, d_i = 0 ~ and ~ d_j = 0) = 1 - \\beta$\n",
    "\n",
    "* $p(x' = s_{nc} |  x = s_{acq}) = 1 $\n",
    "\n",
    "7) Agents can desist from corruption if they stop paying bribes;\n",
    "\n",
    "* $p(x' = s_{des} | x = s_{cor}, d_i = 0 ~ and ~ d_j = 0) = 1 - \\alpha$\n",
    "\n",
    "8) If agents pay bribes again, and they succed, they go back to corruption state;\n",
    "\n",
    "* $p(x' = s_{des} | x = s_{cor},d_i = 1 ~ and ~ d_j=1) = 1 - \\alpha$\n",
    "\n",
    "9) If agents still not paying bribes they stay at desist state if they are not detected;\n",
    "\n",
    "* $p(x' = s_{des} | x = s_{des},  d_i = 0 ~ and ~ d_j = 0) = 1 - \\alpha$\n",
    "\n",
    "10) If agents pay bribes again, and are detected, they go to detected state;\n",
    "\n",
    "* $p(x' = s_{det} | x = s_{cor}, d_i = 1 ~ and ~ dj_ = 1) = \\alpha$\n",
    "\n",
    "11) If agents are reported, they are convicted for sure;\n",
    "\n",
    "* $p(x' = s_{des} | x = s_{con}, d_i \\neq 2 ~ and ~d_j = 2 ) = \\alpha$\n",
    "\n",
    "12) If agents are detected and do not plea guilty, they are convicted if the other agent report or if they not repor with probability $\\beta$;\n",
    "\n",
    "* $p(x' = s_{con} | x = s_{det}, d_i \\neq 2 ~ and ~d_j \\neq 2 ) = \\beta$\n",
    "\n",
    "* $p(x' = s_{con} | x = s_{det}, d_i \\neq 2 ~ and ~d_j = 2 ) = 1$\n",
    "\n",
    "13) If agents are reported they are convicted with certainty;\n",
    "\n",
    "* $p(x' = s_{con} | x = s_{cor}, d_i \\neq 2 ~ and~ d_j = 2 ) = 1$\n",
    "\n",
    "14) If agents plea guilty they will be collaborating with certainty;\n",
    "\n",
    "* $p(x' = s_{col} | x = s_{det}, d_i = 2) = 1$\n",
    "\n",
    "15) If agents report their crimes they will be collaborating with certainty;\n",
    "\n",
    "* $p(x' = s_{col} | x = s_{des}, d_i = 2) = 1$\n",
    "\n",
    "16) If agents report their crimes they will be collaborating with certainty;\n",
    "\n",
    "* $p(x' = s_{col} | x = s_{cor}, d_i = 2) = 1$\n",
    "\n",
    "17) After collaborating with autorities, agents are back to the stage of non corruption;\n",
    "\n",
    "* $p(x' = s_{nc} | x = s_{col}) = 1$\n",
    "\n",
    "18) After convicted by autorities, agents are back to the stage of non corruption;\n",
    "\n",
    "* $p(x' = s_{nc} | x = s_{con}) = 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate all rules into if statements:\n",
    "\n",
    "def rule_1(Si,di,dj):\n",
    "    if Si == s_nc and (di == d_not or dj == d_not): #s_nc , 1\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_2(Si,di,dj):\n",
    "    if Si == s_nc and (di == d_cor and dj == d_cor): #s_cor# , 1 - alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_3(Si,di,dj):\n",
    "    if Si == s_nc and (di == d_cor and dj == d_cor): # s_det #, alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rule_4(Si,di,dj):\n",
    "    if Si == s_cor and (di == d_cor and dj == d_cor): #s_cor #, 1 - alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_5(Si,di,dj):\n",
    "    if Si == s_cor and (di == d_cor or dj == d_cor) and (di != d_rep and dj != d_rep): # s_det# , alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_6_1(Si,di,dj): # s_nc# , 1\n",
    "    if Si == s_acq:\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_6_2(Si,di,dj):    \n",
    "    if Si == s_det and (di == d_not and dj == d_not): # s_acq# , 1 - beta\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_7(Si,di,dj):\n",
    "    if Si == s_cor and (di == d_not or dj == d_not) and (di != d_rep and dj != d_rep):# s_des# , 1 - alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "def rule_8(Si,di,dj):\n",
    "    if Si == s_des and (di == d_cor and dj == d_cor):# s_cor# , 1 - alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "def rule_9(Si,di,dj):\n",
    "    if Si == s_des and (di == d_not or dj == d_not) and (di != d_rep and dj != d_rep):# s_des# , 1 - alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_10(Si,di,dj):\n",
    "    if Si == s_des and (di != d_rep and dj != d_rep):# s_det# , alpha\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_11(Si,di,dj):\n",
    "    if Si == s_des and (di == d_not or di == d_cor) and dj == d_rep:# s_con # , 1 \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rule_12(Si,di,dj):\n",
    "    if Si == s_det:\n",
    "        if (di == d_not and dj == d_not):#  s_con # , beta\n",
    "            return True\n",
    "        elif (di == d_not and dj ==d_rep):# s_con #, 1\n",
    "            return True\n",
    "        else:\n",
    "            return False  \n",
    "        \n",
    "def rule_13(Si,di,dj):\n",
    "    if Si == s_cor and (di == d_not or di == d_cor) and dj == d_rep:# s_con # , 1 \n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "    \n",
    "def rule_14(Si,di,dj):\n",
    "    if Si == s_det and di == d_rep:# s_pg # , 1 \n",
    "        return True\n",
    "    else:\n",
    "        return False   \n",
    "    \n",
    "def rule_15(Si,di,dj):\n",
    "    if Si == s_des and di == d_rep:# s_sr # , 1 \n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "    \n",
    "def rule_16(Si,di,dj):\n",
    "    if Si == s_cor and di == d_rep:# s_sr # , 1\n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "\n",
    "def rule_17(Si,di,dj):\n",
    "    if Si == s_sr or Si == s_pg:# s_nc# , 1\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "def rule_18(Si,di,dj):# s_nc# , 1\n",
    "    if Si == s_con:\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "# Each future state has a unique probability to be achieved\n",
    "def get_prob(Si_prime, Sj_prime ):\n",
    "    if Si_prime == s_nc or Si_prime == s_sr or Si_prime == s_pg or Sj_prime == s_sr or Sj_prime == s_pg :\n",
    "        return 1\n",
    "    elif Si_prime == s_cor or Si_prime == s_des:\n",
    "        return 1 - alpha\n",
    "    elif Si_prime == s_det:\n",
    "        return alpha\n",
    "    elif Si_prime == s_con and Sj_prime == s_con:\n",
    "        return beta\n",
    "    elif Si_prime == s_acq:\n",
    "        return 1 - beta\n",
    "    \n",
    "# Each future statement is feasible from a set of rules:\n",
    "#The following set of functions \n",
    "\n",
    "def get_Si_prime(Si,di,dj):\n",
    "    Si_prime = []\n",
    "    if rule_1(Si,di,dj) or rule_6_1(Si,di,dj) or rule_17(Si,di,dj) or rule_18(Si,di,dj):\n",
    "        Si_prime.append(s_nc)\n",
    "    if rule_2(Si,di,dj) or rule_4(Si,di,dj) or rule_8(Si,di,dj):\n",
    "        Si_prime.append(s_cor)\n",
    "    if rule_7(Si,di,dj)  or rule_9(Si,di,dj):\n",
    "        Si_prime.append(s_des)\n",
    "    if rule_3(Si,di,dj) or rule_5(Si,di,dj) or rule_10(Si,di,dj):\n",
    "        Si_prime.append(s_det)\n",
    "    if rule_11(Si,di,dj) or rule_12(Si,di,dj) or rule_13(Si,di,dj):\n",
    "        Si_prime.append(s_con)\n",
    "    if rule_6_2(Si,di,dj):\n",
    "        Si_prime.append(s_acq)\n",
    "    if rule_15(Si,di,dj) or rule_16(Si,di,dj):\n",
    "        Si_prime.append(s_sr)\n",
    "    if rule_14(Si,di,dj):\n",
    "        Si_prime.append(s_pg)\n",
    "    return Si_prime\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "\n",
    "$$ \\max E_0 \\sum^{\\infty}_{t=0} \\gamma^t u( c_{t}) $$\n",
    "\n",
    "\n",
    "\n",
    "It is possible to define consumption $c_t$ in a certain period as the leftover from consumption:\n",
    "\n",
    "\n",
    "\n",
    "Therfore $u(.)$ is a CCRA function, where;\n",
    "\n",
    "$$u(c) = \\frac{\\displaystyle c ^{(1-\\eta)} - 1 } {1-\\eta} $$\n",
    "\n",
    "Where $\\eta$ is the risk aversion parameter. Where $\\eta > 0$ represents some degree of risk aversion.\n",
    "\n",
    "It is also possible to write $c_t$ as a function of $\\mathbf{x}_{i,t},\\mathbf{d}_{i,t}$:\n",
    "\n",
    "$$ c_t = W_t - w_t - \\phi_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the consumption function:\n",
    "def get_ci(Wi,wi,phi):\n",
    "    return Wi - wi - phi\n",
    "\n",
    "# Define the utility Function\n",
    "\n",
    "def u(c):\n",
    "    if eta != 1:\n",
    "        return (c**(1-eta)-1)/(1-eta)\n",
    "    else:\n",
    "        return ln(c) #import ln function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent's problem:\n",
    "\n",
    "\n",
    "$$ \\max E_0 \\sum^{\\infty}_{t=0} \\gamma^t u( c_{t}) $$\n",
    "\n",
    "s.t.\n",
    "\n",
    "$$W_{i,t+1} = (1+r)w_{i,t} + y_{i,t+1}$$\n",
    "$$L_{i,t+1} = (1-d)L_{i,t} + l_{t+1} $$\n",
    "$$S_{t+1} = f(\\varepsilon, S_t|d_t) $$\n",
    "\n",
    "where, $w_{i,t} =W_t - c_t -\\phi_t$\n",
    "\n",
    "\n",
    "It is possible to rewrite the agent's problem as a value function, such as:\n",
    "\n",
    "$$V(\\mathbf{x}) = \\max_{\\mathbf{x},\\mathbf{x'},\\mathbf{d}} \\{ u(\\mathbf{x}) + \\gamma E[V(\\mathbf{x'})|\\mathbf{x},\\mathbf{d}]\\}$$\n",
    "\n",
    "This is called the Bellman Equation and it is quivallento to:\n",
    "\n",
    "$$V(\\mathbf{x}) = \\max_{\\mathbf{x},\\mathbf{x'},\\mathbf{d}} \\{ R(\\mathbf{x},\\mathbf{d}) + \\gamma V(\\mathbf{x'}) \\Omega(\\mathbf{x'},\\mathbf{d},\\mathbf{x})\\}$$\n",
    "\n",
    "\n",
    "This problem can be solved by iterating the matrix $\\Omega$ through the reward function $R$.\n",
    "\n",
    "Note that the controls $\\mathbf{d}$ which solve the Bellman equation is a pair of decisions. This pair of decisions must hold at the optimum level.\n",
    "\n",
    "So, to solve for the pair or decisions $\\mathbf{d}$, first, we calculate the optimum policy for the payer $\\sigma_{payer}$ using the receiver policy $\\sigma_{receiver}$ as a greedy policy. Such that, \n",
    "\n",
    " \\begin{equation}\n",
    "\t\\sigma(\\mathbf{x}) \\in \\max_{\\mathbf{x},\\mathbf{x'},\\mathbf{u}} \\{ u(\\mathbf{x}) + \\delta \\sum_{\\mathbf{x}}  V^*(\\mathbf{x'})\\Omega(\\mathbf{x'},\\mathbf{u},\\mathbf{x})\\}\n",
    "\t\\label{v4}\n",
    "\\end{equation}\n",
    "\n",
    "The quantecom package DiscreteDP was used to calculate the strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The curse of dimensionality:\n",
    "\n",
    "The set of possible state-action space for both players is imense. It has dimension $(n \\times m)$ where, $n$ is the number of states and pairs and $m$ is their multiplied lenths, or:\n",
    "\n",
    "$n= length(W_i + W_j + L_i + L_j + S_i + S_j + w_i + w_j + d_i + d_j) =  10$ ; and\n",
    "\n",
    "for $\\bar{W} = 10 $ and $\\bar{L} = 5$ then,\n",
    "\n",
    "$m = (\\bar{W}*\\bar{W}*\\bar{L}*\\bar{L}*8*8*\\bar{W}*\\bar{W}*3*3) = 144.000.000$.\n",
    "\n",
    "#### Dimension Reductions:\n",
    "\n",
    "Instead of working with the entire space of controls $\\mathbf{x}$ and states $\\mathbf{d}$ (Sparce Matrices). It is possible to criativelly reduce the diension from the matrices $R$ and $\\Omega$.\n",
    "\n",
    "The two main strategies here are:\n",
    "\n",
    "##### Delimitate then states that players can observe:\n",
    "\n",
    "This is not only a convenient limitation it is a necessary assumption. For instance, it is assumed that agents don't know the wealth $W$ or the assets from the other players. \n",
    "\n",
    "Also, since they are playing sequentially, we can imply that the level of liability from one player is the same as the other. At least it is a good estimation from the player's perspective.\n",
    "\n",
    "Lastly, the path in states of the world $S$ are tied to the players' decisions. Or else, they can estimate the other player' just by knowing ther current state of the world.\n",
    "\n",
    "With these assumption it is possible to estimate the other player decision $j$ as functions from the current observable state.\n",
    "\n",
    "The greedy $\\sigma_{greedy}$ strategy can be defined as:\n",
    "\n",
    "$$\\sigma_{greedy}(\\mathbf{x}) = argmax_{\\mathbf{x},\\mathbf{x'},\\mathbf{d}} \\{ R(\\mathbf{x},\\mathbf{d}) + \\gamma R(\\mathbf{x'}) \\Omega(\\mathbf{x'},\\mathbf{d},\\mathbf{x})\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Space of possibilities in a complete game\n",
    "m_max = (W_bar*W_bar*L_bar*L_bar*len(S_space)*len(S_space)*len(d_space)*len(d_space)*W_bar*W_bar)\n",
    "m_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j's greedy strategy (dj)\n",
    "# since W_j is not observable by i then it is not modeled:\n",
    "# So yc and y0 are the only relevant incomes:\n",
    "\n",
    "def get_dj(player, Si, L_prime ,Wi,Li,Sj): # Two hipothesis  1 - player assumes that receiver is rich.... ore assumes it has the same wealth.\n",
    "    if matrix and [Wi,Li,Si,Sj] in matrix.X_unique[:,:4].tolist(): # If the oplicy is not in sigma, then it returns a greedy policy\n",
    "        return get_di(results.sigma, matrix.X_unique, [Wi,Li,Si,Sj] , matrix.D_unique)\n",
    "    elif Si == s_nc :\n",
    "        if expected_return_i(get_otherplayer(player), L_prime, W_bar) > 0:\n",
    "            return d_cor\n",
    "        else:\n",
    "            return d_not\n",
    "    elif (Si == s_cor or Si == s_des):\n",
    "        if expected_return_i(get_otherplayer(player), L_prime , W_bar) > 0:\n",
    "            return d_cor\n",
    "        elif (expected_return_i(get_otherplayer(player), L_prime, W_bar) > R*get_si(Li ,Si,Sj)):\n",
    "            return d_rep\n",
    "        else:\n",
    "            return 0\n",
    "    elif Si == s_det and beta > P:\n",
    "        return d_rep\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Defines the reduced Sj_space (Only reporting matters)\n",
    "        \n",
    "def get_Sj_prime(Si,di,dj,Si_prime):\n",
    "    if Si_prime in [s_nc , s_cor , s_des , s_det]:  # Agents go always together in these states, and they do not interfere in the number of feasible states.\n",
    "        return Si_prime\n",
    "    elif dj == d_rep and Si !=s_det:\n",
    "        return s_sr\n",
    "    elif dj == d_rep and Si == s_det :\n",
    "        return s_pg\n",
    "    elif dj == d_not and Si_prime in [s_con , s_acq]:\n",
    "        return Si_prime\n",
    "    elif dj in [d_not, d_cor] and di == d_rep:\n",
    "        return s_con\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Feasible State-Action pairs\n",
    "\n",
    "One can reduce the number of state-acion space to only allowed movements in possible states, so the matrices decrease in dimension.\n",
    "\n",
    "* Let $XD$ be the set of only feasible state-action pairs; and\n",
    "\n",
    "* $X$ are the state columns from the matrix and $D$ the action columns.\n",
    "\n",
    "For instance in this exammple, the following rules apply for the states: \n",
    "Importantly, the order matters!\n",
    "\n",
    "1 - It is not possible to pay a bribe if you are not in the no corruption, corruption or desisted state of the world ;\n",
    "\n",
    "2 - There are budget constraints. Or else, It is not possible to pay a bribe without funds;\n",
    "\n",
    "3 - If agent succeded in bribing, state $W$ will be at least $y_t$:\n",
    "\n",
    "4 - If agents are detected their wealth is going to be at most $\\overline{W} - \\phi - s$\n",
    "\n",
    "5 - Agents can only save upt to their wealth at the time;\n",
    "\n",
    "6 - Agents cannot falselly report a crime;\n",
    "\n",
    "7 - The state of the world for each player depends on the other player;\n",
    "\n",
    "8 - In the state s_cor, Liability must be at least 1 or If agents go back to no corruption then there is no liability. Also. if detected, liabiliy state is at least one;\n",
    "\n",
    "9 - The other player's decision must be feasible to the current player decision;\n",
    "\n",
    "10 - ;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PS: In the state transition it is necessary to impose limits to the transitions to maintain the system inside of the boundaries of feasible states. Or else, the sistem transiton cannot lead to state outside the state space. Here, we are excluding state and action pairs that would never be possible to achieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Feasibility rules (f_rules):\n",
    "\n",
    "#################################################################################################\n",
    "#########################    TO DO.... TRY SUBSTITUTING THE RULES BY SIMPLER RULE - > STATE OR ACTION IS FEASIBLE FROM PARAMETERS\n",
    "##########################################################################################################\n",
    "\n",
    "def f_rule_1(Si,di,dj):\n",
    "    '''It is not possible to pay a bribe if you are not in the no corruption, corruption or desisted state of the world'''\n",
    "    if Si in [s_det, s_con,s_acq,s_sr,s_pg] and (di == 1 or dj == 1):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def f_rule_2(Wi,di,dj):\n",
    "    '''There are budget constraints. Or else, It is not possible to pay a bribe without funds'''\n",
    "    if Wi < get_phi_i(player,di,dj):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def f_rule_3(Wi, Si):\n",
    "    '''If agent succeded in bribing, state $W$ will be at least $y_t$:''' \n",
    "    if Si == s_cor and Wi < get_pi_i(player,s_cor):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def f_rule_4(Wi,Li,Si,Sj):\n",
    "    '''If agents are convicted or they plea or self report their wealth is going to be at most $\\overline{W} - S(s_i) $'''\n",
    "    if get_Wi_prime(player, W_bar, Li, Si, Sj) > W_bar:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def f_rule_5(Wi,wi,di,dj):\n",
    "    '''Agents can only save upt to their wealth at the time;'''\n",
    "    if wi > Wi - get_phi_i(player , di , dj):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def f_rule_6(Si,di,dj):\n",
    "    '''Agents cannot falselly report a crime'''\n",
    "    if Si == s_nc and (di == 2 or dj == 2):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def f_rule_7(Si,Sj):\n",
    "    ''' Sj is feasible from Si'''\n",
    "    if (Si in [s_nc , s_cor, s_des, s_det ,s_acq] and (Si != Sj)) \\\n",
    "    or (Si== s_con and Sj not in[s_con, s_sr, s_pg]) \\\n",
    "    or (Sj== s_con and Si not in[s_con, s_sr, s_pg])\\\n",
    "    or (Si == s_sr and Sj == s_pg) \\\n",
    "    or (Si == s_pg and Sj == s_sr):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def f_rule_8(Si,Li):\n",
    "    ''' Minimum Li and maximum Li depending on states'''\n",
    "    if (Si == s_cor and Li < 1) or (Si == s_nc and Li != 0) :\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def f_rule_9(Wi,Li,Si,Sj,dj,di):\n",
    "    ''' dj is feasible'''\n",
    "    if dj != get_dj(player, Si, get_Li_prime(Li , di, dj, s_cor),Wi,Li,Sj): # Complex rationale\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def f_rule_10(Si, di, dj):\n",
    "    ''' In these states, agents cannot do anything'''\n",
    "    if  (Si== s_acq or Si==s_con or Si== s_sr or Si==s_pg) and (di != 0 or dj != 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def apply_fesibility_rules(Wi,Li,Si,Sj,dj,di,wi):\n",
    "    if f_rule_1(Si,di,dj) and f_rule_2(Wi,di,dj) and f_rule_3(Wi, Si) and f_rule_4(Wi,Li,Si,Sj) \\\n",
    "        and f_rule_5(Wi,wi,di,dj) and f_rule_6(Si,di,dj) and f_rule_7(Si,Sj) and f_rule_8(Si,Li) \\\n",
    "            and f_rule_9(Wi,Li,Si,Sj,dj,di) and f_rule_10(Si, di, dj):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the X and D space:\n",
    "\n",
    "def get_feasible_spaces():\n",
    "    XD = [] #creat the vector of the state action pair\n",
    "    for Wi in W_space:\n",
    "        for Li in L_space:\n",
    "            for Si in S_space:\n",
    "                for Sj in S_space:\n",
    "                    for di in d_space:\n",
    "                        for wi in w_space:\n",
    "                            for dj in d_space:\n",
    "                                if apply_fesibility_rules(Wi,Li,Si,Sj,dj,di,wi):\n",
    "                                    XD.append([Wi,Li,Si,Sj,dj,di,wi])\n",
    "\n",
    "    XD = np.asarray(XD)\n",
    "    return XD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the indices\n",
    "#Indices are the maps unique actions and states\n",
    "\n",
    "def get_uniques(XD):\n",
    "    X_unique, indices = np.unique(XD[:,:5], axis=0, return_index=True) #new X space, only with unique feasible states\n",
    "    X_unique = X_unique[np.argsort(indices)] #return unique elements and maintain the original order   \n",
    "    D_unique, indices = np.unique(XD[:,5:], axis=0, return_index=True) #new X space, only with unique feasible states\n",
    "    D_unique = D_unique[np.argsort(indices)] #return unique elements and maintain the original order\n",
    "    return X_unique ,D_unique\n",
    "\n",
    "\n",
    "def extracting_indexes(X_unique,D_unique,XD):\n",
    "    D_indices = []\n",
    "    X_indices = []\n",
    "    for i in range(len(XD)):\n",
    "        D_indices.append(np.where(np.all(D_unique == XD[i][5:],axis=1))[0][0])\n",
    "        X_indices.append(np.where(np.all(X_unique == XD[i][:5],axis=1))[0][0])\n",
    "\n",
    "    D_indices = np.asarray(D_indices)\n",
    "    X_indices = np.asarray(X_indices)\n",
    "\n",
    "    return D_indices , X_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Generating the reward vector \n",
    "\n",
    "Each player has a reward vector $\\textbf{R}$, such that:\n",
    "\n",
    "\\begin{equation*}\n",
    "\t\\mathbf{R} \\equiv\n",
    "\t\\begin{bmatrix}\n",
    "\t\tR_{i} \\\\\n",
    "\t\tR_{j} \n",
    "\t\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "$R_i(x,d)$, of dimension $n$, where $n$ is the number of unique state-action pairs:\n",
    "\n",
    "$$R_i(\\textbf{x},\\textbf{d}) =  \\begin{bmatrix}\n",
    "u_{i,0}(c_{x_0,d_0})\\\\\n",
    "\\vdots \\\\\n",
    "u_{i,n}(c_{x_n,d_n}) \\end{bmatrix}$$\n",
    "\n",
    "where $u_{i}(\\textbf{x},\\textbf{d})$ are the rewards from the state and control pair, where $i \\in [payer,receiver]$ and $j \\in [0,n]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating R for the payer:\n",
    "\n",
    "def populate_Ri(XD):\n",
    "    Ri = []\n",
    "    for i in range(len(XD)):\n",
    "        Ri.append(u(get_ci(XD[i][0],XD[i][6],get_phi_i(player, XD[i][5],XD[i][4]))))\n",
    "    return Ri\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition matrix $\\Omega(\\textbf{x},\\textbf{u},\\textbf{x}')$, of dimension $n \\times m $, can be calculated by:\n",
    "\n",
    "$\\Omega(\\textbf{x},\\textbf{u},) = \\begin{bmatrix}\n",
    " \\begin{bmatrix}\n",
    "p(x_0'|x_0,d_0) \\\\\n",
    "\\vdots\\\\\n",
    "p(x_0'|x_n,d_n) \\end{bmatrix} \\\\\n",
    "\\vdots \\\\\n",
    "\\begin{bmatrix}\n",
    "p(x_m'|x_0,d_0)\\\\\n",
    "\\vdots\\\\\n",
    "p(x_m'|x_n,d_n)  \\end{bmatrix} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Must enter an elif statement to each valid probability to each feasible state:\n",
    "# Each i-row in XD leads to X' with some probability p(X'):\n",
    "# Some i-rows leads to more than one X' with probability p(X') < 1:\n",
    "\n",
    "\n",
    "def find_X_unique_index(i,Si_prime, Sj_prime, X_unique, D_unique, XD):\n",
    "    Li_prime = get_Li_prime(XD[i][1],XD[i][5],XD[i][4],Si_prime)           \n",
    "    Wi_prime = get_Wi_prime(player, XD[i][6],Li_prime , Si_prime, Sj_prime)\n",
    "    dj_prime = get_dj(player, Si_prime, Li_prime,Wi_prime,Li_prime,Sj_prime)\n",
    "    loc_X_unique =  np.array([Wi_prime,Li_prime,Si_prime,Sj_prime,dj_prime])\n",
    "    X_unique_index = np.where(np.all(X_unique==loc_X_unique,axis=1))[0][0]\n",
    "    return X_unique_index\n",
    "\n",
    "def populate_Omega(XD, X_unique, D_unique):\n",
    "    Omega = np.zeros((len(XD),len(X_unique)))\n",
    "    try:\n",
    "        for i in range(len(XD)): # Positions are the columns in X = ([Wi,Li,Si,Sj,dj]), each mean a specific state in X or decision in D (note that dj is a state for player i)\n",
    "            for Si in get_Si_prime(XD[i][2],XD[i][5],XD[i][4]):\n",
    "                Si_prime = Si\n",
    "                Sj_prime = get_Sj_prime(XD[i][2],XD[i][5],XD[i][4],Si_prime)\n",
    "                X_unique_index = find_X_unique_index(i, Si_prime, Sj_prime, X_unique, D_unique, XD)\n",
    "                Omega[i , X_unique_index ]  = get_prob(Si_prime, Sj_prime )\n",
    "    except :\n",
    "        exeption_test(XD,i)\n",
    "        raise\n",
    "    return Omega\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_di(sigma, X_unique, X, D_unique):\n",
    "    sigma_index = np.where(np.all(X_unique[:,:4] == X[:4] ,axis=1))[0][0]\n",
    "    d_index = sigma[sigma_index]\n",
    "    di = D_unique[d_index][0]\n",
    "    return di\n",
    "\n",
    "def get_wi(sigma, X_unique, X, D_unique):\n",
    "    sigma_index = np.where(np.all(X_unique[:,:4] == X[:4] ,axis=1))[0][0] \n",
    "    d_index = sigma[sigma_index]\n",
    "    wi = D_unique[d_index][1]\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Algorithm to find Markovian Perfect Equilibrium\n",
    "\n",
    "1. Solve i's dynamic programming problem when j plays a greedy strategy as given;\n",
    "\n",
    "2. Use the optmal policy ($\\sigma_i$) from i to calculate j's optimal policy ($\\sigma_j$); and\n",
    "\n",
    "3. Compare the policies $|| \\sigma_i - \\sigma_j||$, if they are equal stop, otherwise go to step 2 alternating players. \n",
    "\n",
    "In other words, when players have no incentive to change their strategies given the other player's best responses, it is a Markov Perfect Equilibrium.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Outer Algo, we create a class that computes all the steps above.\n",
    "If we do not pass a policy $\\sigma$, the class returns the $R$ and $\\Omega$ matrices from a greedy 'other player' policy (as well as the state and action indices (X_indices and D_indices).\n",
    "However, if a policy $\\sigma$ is passed, than the best policy from 'other player' is calculated based in the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrices_Maker():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Set up an instance to run the Quantecon routine of discrete dynamic programing.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.XD = get_feasible_spaces()\n",
    "        self.X_unique ,self.D_unique = get_uniques(self.XD)\n",
    "        self.D_indices , self.X_indices = extracting_indexes(self.X_unique,self.D_unique,self.XD)\n",
    "        self.Ri = populate_Ri(self.XD)\n",
    "        self.Omega = populate_Omega(self.XD,self.X_unique,self.D_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_sigma(): # use variables in globals\n",
    "    ''' Iterates the markov function using a new sigma'''\n",
    "    matrix = Matrices_Maker()\n",
    "    ddp = qe.markov.DiscreteDP(matrix.Ri, matrix.Omega, gamma, matrix.X_indices, matrix.D_indices)\n",
    "    results = ddp.solve(method='policy_iteration')\n",
    "    return matrix, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_Matrix_Results(M,R):\n",
    "    global matrix, results\n",
    "    matrix, results = M , R\n",
    "    plot_path_to_steady_state(M,R,W_bar, 50)\n",
    "    vec1 =  get_heatmap_vec_pre(R.sigma, M.X_unique, M.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(R.sigma, M.X_unique, M.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    histogram_stationary(R,M)\n",
    "    \n",
    "def change_global_player():\n",
    "    global player\n",
    "    player = get_otherplayer(player)\n",
    "\n",
    "def create_matrix_results_2(M,R):\n",
    "    global matrix_2,results_2\n",
    "    matrix_2, results_2 = M,R\n",
    "\n",
    "def outer_opearator():\n",
    "    M, R = iterate_sigma()\n",
    "    change_Matrix_Results(M,R)\n",
    "    i = 1\n",
    "    max_it = 10\n",
    "    while i < max_it:\n",
    "        results_1 = results\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_2 = results\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_3 = results\n",
    "        i += 1\n",
    "        if results_1.sigma.shape == results_3.sigma.shape :\n",
    "            if (np.equal(results_1.sigma,results_3.sigma)).all():\n",
    "                print('Success after {} iterations'.format(i-1))\n",
    "                break\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_4 = results\n",
    "        if results_2.sigma.shape == results_4.sigma.shape :\n",
    "            if (np.equal(results_2.sigma,results_4.sigma)).all():\n",
    "                print('Success after {} iterations(Receiv)'.format(i-1))\n",
    "                break\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_5 = results\n",
    "        i += 1\n",
    "        if results_1.sigma.shape == results_5.sigma.shape :\n",
    "            if (np.equal(results_1.sigma,results_5.sigma)).all():\n",
    "                print('No convergence. Started alternating after {} iterations'.format(i-1))\n",
    "                break\n",
    "        if results_3.sigma.shape == results_5.sigma.shape :\n",
    "            if (np.equal(results_3.sigma,results_5.sigma)).all():\n",
    "                print('Converged. Started after {} iterations'.format(i-1))\n",
    "                break\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_6 = results\n",
    "        change_global_player()\n",
    "        create_matrix_results_2(M,R)\n",
    "        M, R = iterate_sigma()\n",
    "        change_Matrix_Results(M,R)\n",
    "        results_7 = results\n",
    "        i += 1\n",
    "        if results_1.sigma.shape == results_7.sigma.shape :\n",
    "            if (np.equal(results_1.sigma,results_7.sigma)).all():\n",
    "                print('No convergence. Started alternating with the first strategy after {} iterations'.format(i-1))\n",
    "                break\n",
    "        if results_3.sigma.shape == results_7.sigma.shape :\n",
    "            if (np.equal(results_3.sigma,results_7.sigma)).all():\n",
    "                print('No convergence. Started alternating after {} iterations'.format(i-1))\n",
    "                break\n",
    "        if results_5.sigma.shape == results_7.sigma.shape :\n",
    "            if (np.equal(results_5.sigma,results_7.sigma)).all():\n",
    "                print('Converged. Started after {} iterations'.format(i-1))\n",
    "                break\n",
    "        print('Finish without converce at the {} iteration'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the constants in globals\n",
    "#fixing random seed for reproducibility\n",
    "\n",
    "player = 'payer'\n",
    "matrix = False\n",
    "b = 3 # Bribe\n",
    "a = 5 # Advantage From Corruption\n",
    "c_b = 1 # Cost of Corrutpion for the receiver\n",
    "f = 5# Fine for corruption\n",
    "alpha = 0.1 # Probability of detection from authorities\n",
    "beta = 0.5 # Probability of judicial conviction\n",
    "ir = 0.05 # Interest Rates\n",
    "delta = 0.1 # Liability Depreciation -> embeded in the desisting rule and in the Maximum Liability\n",
    "gamma = 0.975 # Time discount\n",
    "eta = 0.9 # Risk Aversion\n",
    "y0 = 0 # Non-financial income\n",
    "yl = b # living wage\n",
    "R = 0\n",
    "r = 0.5\n",
    "P = 0.6\n",
    "p = 0.9\n",
    "#increasing problems dimension\n",
    "W_bar = 30\n",
    "L_bar = 5\n",
    "W_space = np.arange(0,W_bar+1)\n",
    "L_space = np.arange(0,L_bar+1)\n",
    "w_space =  np.arange(0,W_bar+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_ICs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_IC_star(R,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6ad83aad86ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mouter_opearator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-f8c14c6878ea>\u001b[0m in \u001b[0;36mouter_opearator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mouter_opearator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate_sigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mchange_Matrix_Results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a39ba498d126>\u001b[0m in \u001b[0;36miterate_sigma\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miterate_sigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# use variables in globals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m''' Iterates the markov function using a new sigma'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatrices_Maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mddp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiscreteDP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOmega\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'policy_iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-c7c73657b50c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \"\"\"\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feasible_spaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_unique\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_uniques\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_indices\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextracting_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_unique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_unique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-d7396f1ea9a0>\u001b[0m in \u001b[0;36mget_feasible_spaces\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mwi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw_space\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0mdj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md_space\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                                 \u001b[1;32mif\u001b[0m \u001b[0mapply_fesibility_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                                     \u001b[0mXD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-68addc9d47a6>\u001b[0m in \u001b[0;36mapply_fesibility_rules\u001b[1;34m(Wi, Li, Si, Sj, dj, di, wi)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_fesibility_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mf_rule_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0mf_rule_5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mf_rule_9\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_rule_10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-68addc9d47a6>\u001b[0m in \u001b[0;36mf_rule_4\u001b[1;34m(Wi, Li, Si, Sj)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf_rule_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;34m'''If agents are convicted or they plea or self report their wealth is going to be at most $\\overline{W} - S(s_i) $'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mget_Wi_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mW_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ea4f5b769cfa>\u001b[0m in \u001b[0;36mget_Wi_prime\u001b[1;34m(player, wi, L_prime, Si_prime, Sj_prime)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_Wi_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfi_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfc_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0myl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0my0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfi_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfc_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mW_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfi_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_yfc_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a1317b9c3d1b>\u001b[0m in \u001b[0;36mget_yfc_prime\u001b[1;34m(player, L_prime, Si_prime, Sj_prime)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_yfc_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_pi_i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mget_si\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSj_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-458ac432ca6a>\u001b[0m in \u001b[0;36mget_pi_i\u001b[1;34m(player, Si)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cost and return functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_pi_i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#return from bribery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mSi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ms_cor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m## substitute by the function S_prime to get pi_prime of d_t.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'payer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "outer_opearator()\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Corruption X Reporting heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 =  get_heatmap_vec_pre(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "vec2 =  get_heatmap_vec_post(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "plot_heatmap(vec1,vec2)\n",
    "player = get_otherplayer(player)\n",
    "vec1 =  get_heatmap_vec_pre(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "vec2 =  get_heatmap_vec_post(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "plot_heatmap(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Path to Steady State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_path_to_steady_state(matrix_2,results_2,50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = get_otherplayer(player)\n",
    "plot_path_to_steady_state(matrix,results,50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the distribution of the steady state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = get_otherplayer(player)\n",
    "histogram_stationary(results,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = get_otherplayer(player)\n",
    "histogram_stationary(results_2,matrix_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Society Results\n",
    "\n",
    "The sampling method, Monte Carlo distribution estimation:\n",
    "\n",
    "\n",
    "1 - Estimate the best strategy to both players $sigma_{payer}$ and $sigma_{receiver}$\n",
    "\n",
    "2 - Assumes a distribution of the wealth in the economy (it is possible to differentiate richer from poorer countries).\n",
    "\n",
    "3 - From fixed initial state ($s_nc$) for 5 periods (Alternative way is to assume an ad hoc distribution from the initial states);\n",
    "\n",
    "4 - Keep the results and plot the distribution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 =vector_sampler(200,5,matrix,matrix_2,results,results_2,0,1)\n",
    "print('Benchmark')\n",
    "histogram_sampling(sample_1, 'Normal')\n",
    "sample_2 =vector_sampler(200,5,matrix,matrix_2,results,results_2,W_bar/4,1)\n",
    "print('Richer')\n",
    "histogram_sampling(sample_2,'Richer')\n",
    "sample_3 =vector_sampler(200,5,matrix,matrix_2,results,results_2,-W_bar/4,1)\n",
    "print('Poorer')\n",
    "histogram_sampling(sample_3,'Poorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Benchmark')\n",
    "histogram_sampling_savings(sample_1, 'Normal')\n",
    "print('Richer')\n",
    "histogram_sampling_savings(sample_2, 'Richer')\n",
    "print('Poorer')\n",
    "histogram_sampling_savings(sample_3, 'Poorer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* As it was supposed to happen, the players pay bribes untill that their utility from current wealth is lower than the expected walth gained from corrupion.\n",
    "\n",
    "* After this, they stop colluding at their wealth level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Studies\n",
    "\n",
    "Set the problem for a complete game to run in a super-computer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactioring Notes\n",
    "\n",
    "1) The operators iterate the parameters and variables as global variables. Put the inside functions or objects;\n",
    "\n",
    "2) Fix the player variable;\n",
    "\n",
    "3) Simplify the feasibility rules;\n",
    "\n",
    "4) Make sanctions only function of states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "alphas = [0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.2,0.3,0.3,0.3,0.3]\n",
    "betas = [0.6,0.7,0.8,0.9,0.6,0.7,0.8,0.9,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for i,j in zip(alphas,betas):\n",
    "    print('NEW ITERATION WITH ALPHA {} AND BETA {}'.format(i,j))\n",
    "    matrix = False\n",
    "    player = 'payer'\n",
    "    alpha = i\n",
    "    beta = j\n",
    "    outer_opearator()\n",
    "    vec1 =  get_heatmap_vec_pre(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    vec1 =  get_heatmap_vec_pre(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix,results,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix_2,results_2,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results,matrix)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    sample_1 =vector_sampler(200,5,matrix,matrix_2,results,results_2,0,1)\n",
    "    print('Benchmark')\n",
    "    histogram_sampling(sample_1, 'Normal')\n",
    "    sample_2 =vector_sampler(200,5,matrix,matrix_2,results,results_2,W_bar/4,1)\n",
    "    print('Richer')\n",
    "    histogram_sampling(sample_2,'Richer')\n",
    "    sample_3 =vector_sampler(200,5,matrix,matrix_2,results,results_2,-W_bar/4,1)\n",
    "    print('Poorer')\n",
    "    histogram_sampling(sample_3,'Poorer')\n",
    "    print('Benchmark')\n",
    "    histogram_sampling_savings(sample_1, 'Normal')\n",
    "    print('Richer')\n",
    "    histogram_sampling_savings(sample_2, 'Richer')\n",
    "    print('Poorer')\n",
    "    histogram_sampling_savings(sample_3, 'Poorer')\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "alpha = 0.1\n",
    "beta = 0.6\n",
    "\n",
    "\n",
    "Rs =[1,0.5,0.2,0.2,0,0,-0.5, -1]\n",
    "rs =[1,0.5,0.5,0.5,0.4,0.4,0, 0]\n",
    "Ps =[1,0.5,0.6,0.5,0.6,0.5,0.5, 0]\n",
    "ps =[1,0.5,0.9,0.7,0.9,0.7,0.6, 0.5]\n",
    "\n",
    "for i,j,k,l in zip(Rs,rs,Ps,ps):\n",
    "    print('NEW ITERATION WITH R =  {}, r = {}, P = {} and p = {}'.format(i,j,k,l))\n",
    "    matrix = False\n",
    "    player = 'payer'\n",
    "    R = i\n",
    "    r = j\n",
    "    P = k\n",
    "    p = l\n",
    "    get_IC_star(R,P)\n",
    "    outer_opearator()\n",
    "    vec1 =  get_heatmap_vec_pre(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    vec1 =  get_heatmap_vec_pre(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix,results,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix_2,results_2,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results,matrix)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    sample_1 =vector_sampler(200,5,matrix,matrix_2,results,results_2,0,1)\n",
    "    print('Benchmark')\n",
    "    histogram_sampling(sample_1, 'Normal')\n",
    "    sample_2 =vector_sampler(200,5,matrix,matrix_2,results,results_2,W_bar/4,1)\n",
    "    print('Richer')\n",
    "    histogram_sampling(sample_2,'Richer')\n",
    "    sample_3 =vector_sampler(200,5,matrix,matrix_2,results,results_2,-W_bar/4,1)\n",
    "    print('Poorer')\n",
    "    histogram_sampling(sample_3,'Poorer')\n",
    "    print('Benchmark')\n",
    "    histogram_sampling_savings(sample_1, 'Normal')\n",
    "    print('Richer')\n",
    "    histogram_sampling_savings(sample_2, 'Richer')\n",
    "    print('Poorer')\n",
    "    histogram_sampling_savings(sample_3, 'Poorer')\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "R = 0.1\n",
    "r = 0.5\n",
    "P = 0.6\n",
    "p = 0.9\n",
    "\n",
    "irs = [0.02,0.05,0.1,0.16,0.2,0.3]\n",
    "\n",
    "for i in irs:\n",
    "    print('NEW ITERATION WITH Interests {}'.format(i))\n",
    "    matrix = False\n",
    "    player = 'payer'\n",
    "    ir = i\n",
    "    outer_opearator()\n",
    "    vec1 =  get_heatmap_vec_pre(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    vec1 =  get_heatmap_vec_pre(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix,results,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix_2,results_2,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results,matrix)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    sample_1 =vector_sampler(200,5,matrix,matrix_2,results,results_2,0,1)\n",
    "    print('Benchmark')\n",
    "    histogram_sampling(sample_1, 'Normal')\n",
    "    sample_2 =vector_sampler(200,5,matrix,matrix_2,results,results_2,W_bar/4,1)\n",
    "    print('Richer')\n",
    "    histogram_sampling(sample_2,'Richer')\n",
    "    sample_3 =vector_sampler(200,5,matrix,matrix_2,results,results_2,-W_bar/4,1)\n",
    "    print('Poorer')\n",
    "    histogram_sampling(sample_3,'Poorer')\n",
    "    print('Benchmark')\n",
    "    histogram_sampling_savings(sample_1, 'Normal')\n",
    "    print('Richer')\n",
    "    histogram_sampling_savings(sample_2, 'Richer')\n",
    "    print('Poorer')\n",
    "    histogram_sampling_savings(sample_3, 'Poorer')\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "ir = 0.05\n",
    "\n",
    "\n",
    "a =[2,4,3,5,6,6,10,15,20,8]\n",
    "b =[1,1,2,3,3,4,5,10,12,2]\n",
    "c_b =[0,0,0,1,1,1,5,2,0]\n",
    "f =[2,4,3,5,6,6,10,15,20,8]\n",
    "\n",
    "for i,j,k,l in zip(a,b,c_b,f):\n",
    "    print('NEW ITERATION WITH a =  {}, b = {}, c_b = {} and f = {}'.format(i,j,k,l))\n",
    "    matrix = False\n",
    "    player = 'payer'\n",
    "    a = i\n",
    "    b = j\n",
    "    c_b = k\n",
    "    f = l\n",
    "    get_IC_star(R,P)\n",
    "    outer_opearator()\n",
    "    print('RESULTS IN EQUILIBRIUM')\n",
    "    vec1 =  get_heatmap_vec_pre(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results.sigma, matrix.X_unique, matrix.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    vec1 =  get_heatmap_vec_pre(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    vec2 =  get_heatmap_vec_post(results_2.sigma, matrix_2.X_unique, matrix_2.D_unique)\n",
    "    plot_heatmap(vec1,vec2)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix,results,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    plot_path_to_steady_state(matrix_2,results_2,50, 50)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results,matrix)\n",
    "    player = get_otherplayer(player)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    histogram_stationary(results_2,matrix_2)\n",
    "    sample_1 =vector_sampler(200,5,matrix,matrix_2,results,results_2,0,1)\n",
    "    print('Benchmark')\n",
    "    histogram_sampling(sample_1, 'Normal')\n",
    "    sample_2 =vector_sampler(200,5,matrix,matrix_2,results,results_2,W_bar/4,1)\n",
    "    print('Richer')\n",
    "    histogram_sampling(sample_2,'Richer')\n",
    "    sample_3 =vector_sampler(200,5,matrix,matrix_2,results,results_2,-W_bar/4,1)\n",
    "    print('Poorer')\n",
    "    histogram_sampling(sample_3,'Poorer')\n",
    "    print('Benchmark')\n",
    "    histogram_sampling_savings(sample_1, 'Normal')\n",
    "    print('Richer')\n",
    "    histogram_sampling_savings(sample_2, 'Richer')\n",
    "    print('Poorer')\n",
    "    histogram_sampling_savings(sample_3, 'Poorer')\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r /content/Plottings.zip /content/Plottings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
